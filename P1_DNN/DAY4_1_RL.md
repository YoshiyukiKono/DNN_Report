# DAY4 
## 強化学習

### 強化学習とは

- 長期的に報酬を最大化できるように、環境の中で、行動を選択できるエージェントを作ることを目標とする。

- 行動の結果として、与えられる利益（報酬）をもとに、行動を決定する原理を改善していく仕組み

### 強化学習の応用例

- 環境：販売促進部門
- エージェント：プロフィールと購入履歴に基づいて、キャンペーンメールを送る顧客を決定するソフトウェア
- 行動：顧客ごとに送信、非送信の行動を選択する
- 報酬：
   - キャンペーンのコスト（負の報酬）
   - キャンペーンで生み出されると推測される売り上げ（正の報酬）

### 探索と利用のトレードオフ

- 不完全な知識を基に行動しながら、データを収集し最適な行動を見つけていく。

- 過去のデータを基に行動するだけでは、よりよい行動を見つけることができない（探索が足りていない）
- より良い行動を見つけるために、ランダムな探索的行動をしているだけでは、過去の経験を利用した成果を上げることができない


### 強化学習のイメージ

- エージェント
   - 方策関数： TT(s, a)
   - 行動価値関数：Q(s, a)

これらの関数を学習させる

### 強化学習の差分

- 教師あり学習や教師なし学習では、データに含まれるパターンを見つけ出し、データから予測することが目標

- 強化学習では、優れた方策を見つけることが目標

#### 強化学習の歴史

関数近似法とＱ学習を組み合わせる手法の登場により進歩

##### Ｑ学習
行動価値関数を、行動するごとに更新することにより学習を進める方法

##### 関数近似法
価値関数や方策関数を関数近似する手法

### 価値関数

- 状態価値関数
   - 環境の状態だけが価値を決める要因。
- 行動価値関数
   - 行動が価値を決める要因となる。状態と価値を組み合わせる。

ゲームに勝てそうかどうかを決める関数

### 方策関数
ある状態でどのような行動をとるかの確率を与える関数

π(s) = a

ゲームの一手を打つための関数

### 1-8 方策勾配法

π(s, a | Θ)

#### 方策反復法
方策をモデル化して最適化する手法


```
Θ^(t+1) = Θ^t + ε∇J(Θ)
```
- Θ：NNでいうところの重み

方策の良さ（J）は定義しなければならない

NNでは、誤差を小さくなるように学習をする
強化学習では、期待収益（報酬）が大きくなるように学習をする

定義方法
- 平均報酬
- 割引報酬和

- 上記の定義に対応して、行動価値関数:Q(s,a)の定義を行う。
- 方策勾配定理が成り立つ。


## Alpha Go

### AlphaGo Lee


#### Policy Net

19 X 19マスの着手予想確率を出力する(２次元データ：SoftMax Layer)

#### Value Net

出力は、現局面の勝率を-1 ~ 1であらわしたもの（バイナリデータ：TanH Layer)

### 強化学習ステップ

- 教師あり学習によるRollOutPolicyとPolicyNetの学習
- 強化学習によるPolicyNetの学習
  - PolicyNetとPolicyPoolからランダムに選択されたPolicyNetと対局シミュレーションを行う。
- 強化学習によるValueNetの学習

#### RollOut Policy

PollicyNetよりも100倍速い

#### モンテカルロ木探索
強化学習手法。

### AlphaGo Zero
- 教師あり学習を行わず、強化学習のみで作成
- 特徴入力からヒューリスティックな要素（人間が役に立つと判断し付加した情報）を排除、石の配置のみとした。
- PolicyNetとValueNetをひとつのネットワークに統合
- Residual Netを導入
- モンテカルロ木探索からRollOutシミュレーションをなくした



#### Residual Net/Block
- ネットワークにショートカットを作る(勾配消失・爆発が起きづらくなる)
- 100層を超えるネットワークで安定した学習が可能になった(AlphaGo Zeroでは39層)
- Convolution > BatchNorm > ReLU > Concolution > BatchNorm > Add(ショートカットの入力) > ReLUという構造
- ショートカットにより、層数の違うNetworkのアンサンブル効果が得られる

AlphaGo Zeroでは、この後に、二つの出力（PolicyとValue）に経路を分割する。



##### AlphaGo Zeroでの工夫
###### Residual Blockに対する工夫
- Bottleneck
  - １層目で次元削減を行い、３層目で次元復元
- PreActivation
  - BatchNorm > ReLU > Convolution > BatchNorm > ReLU > Convolution > Add

###### Network構造に対する工夫
- WideResNet
   - ConvolutionのFilter数をK倍にしたResNet
   - GPUを効率的に利用
- PyramidNet
   - WideResNetに対する改良
   - 各層でFilter数を増やしていくResNet

## 軽量化・高速化技術

#### 分散深層学習
複数の計算資源（ワーカー）を使用し、並列的にニューラルネットを構成することで効率の良い学習を行う



### データ並列化
- 親モデルを各ワーカーに子モデルとしてコピー
- データを分割し、各ワーカーごとに計算させる

#### 同期型
各ワーカーが計算が終わるのを待ち、全ワーカーの勾配が出たところで勾配の平均を計算し、親モデルのパラメータを更新する

#### 非同期型
学習が終わった子モデルは、パラメータサーバにプッシュされる。新たに学習をする際には、パラメータサーバからPopしたモデルに対して学習していく。

- 学習が不安定になりやすい：Stale Gradient Problem

### モデル並列化
親モデルを分割し、各ワーカーでモデルを学習させる。学習が終わった後に一つのモデルに復元

- モデル大：モデル並列化
- データ大：データ並列化

モデルのパラメータ数が多いほど、スピードアップの効率も向上する

#### 参照論文

##### Large Scale Distributed Deep Networks
Google 2016年

### GPU

#### GPGPU (General-purpose on GPU)
グラフィック以外の用途で使用されるGPUの総称

#### CUDA
NVIDIA社GPU用並列コンピューティングプラットフォーム

#### OpenCL
オープンな並列コンピューティングのプラットフォーム

## モデル軽量化
### 量子化 Quantization

64bit(4byte)浮動小数点を32bit(4byte), 16bit(2byte)等下位の精度に落とすことでメモリと演算処理の削減を行う

#### 省メモリ化
ニューロンの重みを浮動小数点のbit数を少なくし、有効桁数を下げることで、ニューロンのメモリサイズを小さくする

- 16bit: 5bit exponent + 10bit fraction: 0.xxxxx X 10^5
- 64bit: 11bit exponent + 52bit fraction: 0.xxxxxxxxxxx X 10^11

#### 量子化の利点と欠点
##### 利点
- 計算の高速化
- 省メモリ化
##### 欠点
- 精度の低下

#### 計算の高速化
- 倍精度演算(64bit)
- 単精度演算(32bit)
- 半精度演算(16bit)

- FLOPS(FLoating OPerationS)

#### 精度の低下

ほとんどの場合、半精度で十分。

#### 極端な量子化

量子化する際には、極度に精度が落ちない程度に量子化しなければならない。


### 蒸留

すでに存在する規模の大きなモデルの知識を使い軽量なモデルの作成を行う。

#### モデルの簡約化
知識の継承により、軽量ながら複雑なモデルに匹敵する精度のモデルを得ることを期待

#### 教師モデルと生徒モデル
##### 教師モデル
予測精度の高い、複雑なモデルやアンサンブルされたモデル
##### 生徒モデル
教師モデルをもとに作られる軽量なモデル

教師モデルの重みを固定し、生徒モデルの重みを更新していく。
誤差は教師モデルと生徒モデルのそれぞれの誤差を使い重みを更新していく

#### 蒸留の利点
- Knowledge Distilation (教師モデルと生徒モデル)
- Hint Training


### プルーニング

ネットワークが大きくなると大量のパラメータになるが、すべてのニューロンの計算が精度に寄与しているわけではない。

#### ニューロンの削減

重みが閾値以下の場合、ニューロンを削減し、再学習を行う。

#### ニューロン数と精度
閾値を高くするとニューロンは大きく削減できるが、精度も減少する。


## 応用技術
### MobileNet

- 軽量化・高速化・高精度化を実現
- 畳み込み演算を工夫

#### 一般的な畳み込み
- 
一般的な畳み込み（１回）の計算量：K (Kernel W) x K (Kernel H) x C (Channel) x M (Filter)

一般的な畳み込みの計算量：H x W x K (Kernel W) x K (Kernel H) x C (Channel) x M (Filter)

#### Depthwise Convolution
- フィルタ数は１
- 入力マップのチャンネルごとに畳み込みを実施
- 出力マップをそれらと結合（入力マップのチャンネル数を同じになる）

畳み込みの計算量：H x W x K (Kernel W) x K (Kernel H) x C (Channel)

#### Pointwise Convolution
- カーネルサイズを1x1に固定、フィルタ数：M
- 1x1 convとも呼ばれる　(1x1xc)
- 出力マップはフィルタ数分だけ作成可能（任意のサイズが指定可能）

一般的な畳み込みの計算量：H x W x C (Channel) x M (Filter)

#### まとめ
- Depthwise Separable Convolutionによって計算量削減
- Depthwise Convolusionの計算量は、1/M
- Depthwise Convolusionの計算量は、1/(k x k)
- Depthwise Convolusionの計算量は、H W C K K + H W C M (通常は、H W K K C M)

1/40のメモリ量で済む

### DenseNet
画像認識のネットワーク

- 初期畳み込み
- Dense Block
- 変換レイヤー
- 判別レイヤー

#### Dense Block
- Batch正規化
- Reluによる変換
- 3x3畳み込み層による処理

- 入力特徴マップを各ブロックの入力として付け加えられる
- 二つ前以前のブロックの出力もひとつ前のブロックの出力とともに付け加えられる
  - ネットワークのgrouth rate：k
   - 入力：　k0 + nK
- Transition Layer と呼ばれる層でDense Blockをつなぐ（Convolution + Pooling）

##### DenseNetとResNetの違い
スキップコネクションが存在するネットワークとしてRes(ssidual)Netがある
- Ressidual Blockでは、前１層の入力のみ後方の層へ入力

### Batch Normalization
- レイヤー間を流れるデータの分布をミニバッチ単位で平均０、分散１になるよう正規化
- 学習時間の短縮や初期値への依存提言、過学習の抑制など効果がある

ミニバッチに含まれるサンプルの同一チャンネルが同一分布になるよう正規化（チャンネルごとに正規化された特徴マップを出力）

#### 問題点
バッチサイズが小さい条件下では効果が薄く、学習が収束しないこともあるためLayer Normを使う

### Layer正規化

それぞれのサンプルのすべてのピクセルが同一分布に従うよう正規化

- 入力データのスケールに関してロバスト
- 重み行列のスケールやシフトに関してロバスト

### Instance正規化

LayerNormに加え、チャンネルも同一分布に従うよう正規化

- コントラストの正規化に寄与
- 画像のスタイル転送やテクスチャ合成タスクなどで利用


### Wavenet

時系列データに対して畳み込み(Dilated convolution)を適用する音声生成モデル

#### Dilated (causal) convolution
- 層が深くなるにつれて畳み込むリンクを離す
- 受容野を簡単に増やすことができる利点がある
- パラメータ数に対する受容野が広い（単純なConvolution layerと比べて）


##### Deconvolution/逆畳み込み
画像のピクセル数を増やす・解像度を上げる。
