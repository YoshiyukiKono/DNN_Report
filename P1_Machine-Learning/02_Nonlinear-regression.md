# 非線形回帰モデル

## 基底展開法
- 基底関数と呼ばれる既知の非線形関数とパラメータベクトルの線形結合を使用
- 未知パラメータは線形回帰モデルと同様に最小二乗法や最尤法により推定

## 基底関数
- 多項式関数（１～９次）
- ガウス型基底
- スプライン関数/Bスプライン関数

## 未学習(underfitting)と過学習(overfitting)その対策
### 未学習
誤差が小さくならないモデル

- 表現力の高いモデルを利用
### 過学習
誤差は小さいが、テスト集合誤差との差が大きいモデル

- 学習データの株を増やす
- モデルの複雑さを調整する
  - 不要な基底関数（変数）を削除して表現力を抑止
  - 正則化法を利用して表現力を抑止

## 正則化法（罰則化法）

### L1ノルム（Lasso推定量）
いくつかのパラメータを正確に0に推定

縮小推定

### L2ノルム（Ridge推定量）
パラメータを0に近づけるよう推定

スパース推定

## 汎化性能

学習に使用した入力だけでなく、これまで見たことのない新たな入力に対する予測性能

(学習誤差ではなく)汎化誤差(テスト誤差)が小さいものが良い性能を持ったモデル。

汎化誤差は通常、学習データとは別に収集された検証データでの性能を測ることで推定

### バイアス・バリアンス
- 過学習制御 小:
  - 訓練データに対してはフィットするためバイアスは小 
  - データ依存により生ずるバリアンスは大

- 過学習制御 大:
  - 訓練データにすらフィッティングできなくなりバイアスは大
  - 訓練データへの依存度であるバリアンスは小 

[バイアス-バリアンス分解：機械学習の性能評価](https://lms.quizgenerator.net/sys/index.php?action=quizPlayer&options=eyJzY29faWQiOiIxMjE3MTI3IiwiYmFja19saXN0Ijp0cnVlLCJoZWFkZXIiOnsiZ29vZCI6eyJ2aXNpYmxlIjp0cnVlfX19)

## データの分割とモデルの汎化性能測定

### 交差検証法 クロスバリデーション

データをk分割し、学習用(k-1)と評価用(1)に分割し、学習データによる訓練、検証データによる精度計測をデータセットを変えてk回実行。

### ホールドアウト法
- 有限のデータを学習用とテスト用の2つに分割し、「予測精度」や「誤り率」を推定する為に使用
- 学習用を多くすればテスト用が減り学習精度は良くなるが、性能評価の精度は悪くなる
- 逆にテスト用を多くすれば学習用が減少するので、学習そのものの精度が悪くなることになる。
- 手元にデータが大量にある場合を除いて、良い性能評価を与えないという欠点がある。

ホールドアウトの性能がＣＶより高くても、ＣＶの精度を採用すべき。

## グリッドサーチ
- 全てのチューニングパラメータの組み合わせで評価値を算出
- 最も良い評価値を持つチューニングパラメータを持つ組み合わせを、「いいモデルのパラメータ」として採用

